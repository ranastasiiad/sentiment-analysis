{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a54e5246",
   "metadata": {},
   "outputs": [],
   "source": [
    "# работа с данными\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# графики\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt \n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "\n",
    "# настройка графиков\n",
    "# matplotlib.rcParams['figure.figsize'] = (8, 8)\n",
    "# sns.set_style('whitegrid')\n",
    "\n",
    "# предупреждения\n",
    "import warnings \n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "\n",
    "# tqdm\n",
    "from tqdm.notebook import tqdm\n",
    "# time\n",
    "import itertools\n",
    "# copy\n",
    "from copy import deepcopy\n",
    "\n",
    "# работа с файлами\n",
    "import pickle\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e7ae4c71",
   "metadata": {},
   "outputs": [],
   "source": [
    "#unlabeled = pd.read_csv(\"C:/Users/ranas/ML course/Competitions/Second competition/data/raw/unlabeled_data.csv\")\n",
    "train  = pd.read_csv(\"C:/Users/ranas/ML course/Competitions/Second competition/data/raw/train.csv\")\n",
    "test = pd.read_csv(\"C:/Users/ranas/ML course/Competitions/Second competition/data/raw/test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d6436d82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>c77111d1e3526ac0f7cf13af46b65e65</td>\n",
       "      <td>1</td>\n",
       "      <td>I thought the film could be a bit more complex...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>c4806c50f6560aa65f15ed69a25940f2</td>\n",
       "      <td>0</td>\n",
       "      <td>...except for Jon Heder. This guy tanked the e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>82b113c68594c74ab8dbe630206ec28a</td>\n",
       "      <td>1</td>\n",
       "      <td>Jim Carrey is good as usual, and even though t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3d9891905de05248dfc2550239bd4687</td>\n",
       "      <td>1</td>\n",
       "      <td>Just read the original story which is written ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>da8d5a23f01e129b534022149825caa2</td>\n",
       "      <td>1</td>\n",
       "      <td>I watched this film over a hundred times. It i...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 id  sentiment  \\\n",
       "0  c77111d1e3526ac0f7cf13af46b65e65          1   \n",
       "1  c4806c50f6560aa65f15ed69a25940f2          0   \n",
       "2  82b113c68594c74ab8dbe630206ec28a          1   \n",
       "3  3d9891905de05248dfc2550239bd4687          1   \n",
       "4  da8d5a23f01e129b534022149825caa2          1   \n",
       "\n",
       "                                              review  \n",
       "0  I thought the film could be a bit more complex...  \n",
       "1  ...except for Jon Heder. This guy tanked the e...  \n",
       "2  Jim Carrey is good as usual, and even though t...  \n",
       "3  Just read the original story which is written ...  \n",
       "4  I watched this film over a hundred times. It i...  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cd33578c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I thought the film could be a bit more complex,in a psychological sense perhaps, but the action and voice acting were top notch. The animation was heavy CG in many scenes, but very good ones at that. This is one of the Batman Returns/Forever type films, which include romances and the conflicts of Wayne and motives for dating. 007 fans would love this, and so would the females, great theme song! Wayne was portrayed very well in this film, and the Penquin was back to his true form, no mutant genes in him this time! I liked the fact Robin wasn't used too much, Tim Drake was just a good computer nerd, somewhat of an Indigo child or mind of the future.<br /><br />The supporting cast was made up of some soap opera stars, decent talents and the characters were drawn to look like the voice actors too. Kelly Ripa was hilarious in this film.<br /><br />I rate this below Phantasm, Return of the Joker, and Batman vs. Dracula, but liked the smarter script better than I enjoyed Subzero. 7/10\""
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['review'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36d761ba",
   "metadata": {},
   "source": [
    "### Vader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8251badf",
   "metadata": {},
   "source": [
    "Valence Aware Dictionary for sEntiment Reasoning\n",
    "\n",
    "his lexical dictionary does not only contain words, but also phrases (such as “bad ass” and “the bomb”), emoticons (such as “:-)”) and sentiment-laden acronyms (such as “ROFL” and “WTF”). All the lexical features were rated for the polarity and intensity on a scale from “-4: Extremely Negative” to “+4 Extremely Positive” by 10 independent human raters. The average score is then used as the sentiment indicator for each lexical feature in the dictionary. For example, in Vader, the word “okay” has a positive rating of 0.9, “good” is 1.9 and “great” is 3.1, whereas “horrible” is -2.5, the frowning emoticon “:(“ is -2.2, and “sucks” is -1.5. Vader’s lexicon dictionary contains around 7,500 sentiment features in total and any word not listed in the dictionary will be scored as “0: Neutral”."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9c7d6e5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     C:\\Users\\ranas\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('vader_lexicon')\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "sia = SentimentIntensityAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5ccfae89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'neg': 0.0, 'neu': 0.318, 'pos': 0.682, 'compound': 0.6468}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sia.polarity_scores('I am so happy!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f8c6da8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'neg': 0.039, 'neu': 0.663, 'pos': 0.298, 'compound': 0.9963}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sia.polarity_scores(train['review'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3b9296f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'neg': 0.188, 'neu': 0.689, 'pos': 0.123, 'compound': -0.8989}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sia.polarity_scores(train['review'][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9f8b028f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'neg': 0.04, 'neu': 0.799, 'pos': 0.161, 'compound': 0.7904}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sia.polarity_scores(train['review'][2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e563595a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'neg': 0.021, 'neu': 0.728, 'pos': 0.251, 'compound': 0.9437}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sia.polarity_scores(train['review'][3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f73f1a7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'neg': 0.0, 'neu': 0.508, 'pos': 0.492, 'compound': 0.9694}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sia.polarity_scores(train['review'][4])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fc7e596",
   "metadata": {},
   "source": [
    "А оно неплохо справляется!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "be5c7f6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f90ec1da87694b87b513ba5c9f6e03c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "res = {}\n",
    "for i, row in tqdm(train.iterrows(), total=len(train)):\n",
    "    text = row['review']\n",
    "    myid = row['id']\n",
    "    res[myid] = sia.polarity_scores(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f6e390c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "vaders = pd.DataFrame(res).T\n",
    "vaders = vaders.reset_index().rename(columns={'index': 'id'})\n",
    "vaders = vaders.merge(train, how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "39f2e5c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>neg</th>\n",
       "      <th>neu</th>\n",
       "      <th>pos</th>\n",
       "      <th>compound</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>c77111d1e3526ac0f7cf13af46b65e65</td>\n",
       "      <td>0.039</td>\n",
       "      <td>0.663</td>\n",
       "      <td>0.298</td>\n",
       "      <td>0.9963</td>\n",
       "      <td>1</td>\n",
       "      <td>I thought the film could be a bit more complex...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>c4806c50f6560aa65f15ed69a25940f2</td>\n",
       "      <td>0.188</td>\n",
       "      <td>0.689</td>\n",
       "      <td>0.123</td>\n",
       "      <td>-0.8989</td>\n",
       "      <td>0</td>\n",
       "      <td>...except for Jon Heder. This guy tanked the e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>82b113c68594c74ab8dbe630206ec28a</td>\n",
       "      <td>0.040</td>\n",
       "      <td>0.799</td>\n",
       "      <td>0.161</td>\n",
       "      <td>0.7904</td>\n",
       "      <td>1</td>\n",
       "      <td>Jim Carrey is good as usual, and even though t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3d9891905de05248dfc2550239bd4687</td>\n",
       "      <td>0.021</td>\n",
       "      <td>0.728</td>\n",
       "      <td>0.251</td>\n",
       "      <td>0.9437</td>\n",
       "      <td>1</td>\n",
       "      <td>Just read the original story which is written ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>da8d5a23f01e129b534022149825caa2</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.508</td>\n",
       "      <td>0.492</td>\n",
       "      <td>0.9694</td>\n",
       "      <td>1</td>\n",
       "      <td>I watched this film over a hundred times. It i...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 id    neg    neu    pos  compound  sentiment  \\\n",
       "0  c77111d1e3526ac0f7cf13af46b65e65  0.039  0.663  0.298    0.9963          1   \n",
       "1  c4806c50f6560aa65f15ed69a25940f2  0.188  0.689  0.123   -0.8989          0   \n",
       "2  82b113c68594c74ab8dbe630206ec28a  0.040  0.799  0.161    0.7904          1   \n",
       "3  3d9891905de05248dfc2550239bd4687  0.021  0.728  0.251    0.9437          1   \n",
       "4  da8d5a23f01e129b534022149825caa2  0.000  0.508  0.492    0.9694          1   \n",
       "\n",
       "                                              review  \n",
       "0  I thought the film could be a bit more complex...  \n",
       "1  ...except for Jon Heder. This guy tanked the e...  \n",
       "2  Jim Carrey is good as usual, and even though t...  \n",
       "3  Just read the original story which is written ...  \n",
       "4  I watched this film over a hundred times. It i...  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vaders.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0832cf78",
   "metadata": {},
   "outputs": [],
   "source": [
    "vaders['predict'] = np.where(vaders['compound']>0,1,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "55233340",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 0.6956\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "train_metric = accuracy_score(\n",
    "    y_true=vaders['sentiment'],\n",
    "    y_pred=vaders['predict']\n",
    ")\n",
    "\n",
    "print(f\"Accuracy score: {round(train_metric, 4)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83afbd5e",
   "metadata": {},
   "source": [
    "### Roberta pretrained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "be3ad029",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "from transformers import AutoModelForSequenceClassification\n",
    "from scipy.special import softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "cc0dd63d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "81058d15794b41709c7d8d316767c338",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/747 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ranas\\anaconda3\\lib\\site-packages\\huggingface_hub\\file_download.py:123: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\ranas\\.cache\\huggingface\\hub. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "803208d9a89a42f1bcd6e7e299904f71",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/899k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "417e0eb1cce24cc6b02e70a17960c0f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "97ad2e8cf6f34f5e89dfd7a827ef79ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/150 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5096a6c3a23549949372e48a094ee219",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/499M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "MODEL = f\"cardiffnlp/twitter-roberta-base-sentiment\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(MODEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "007ba94b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'roberta_neg': 0.0050721676, 'roberta_neu': 0.047950763, 'roberta_pos': 0.9469772}\n"
     ]
    }
   ],
   "source": [
    "encoded_text = tokenizer(train['review'][0], return_tensors='pt')\n",
    "output = model(**encoded_text)\n",
    "scores = output[0][0].detach().numpy()\n",
    "scores = softmax(scores)\n",
    "scores_dict = {\n",
    "    'roberta_neg' : scores[0],\n",
    "    'roberta_neu' : scores[1],\n",
    "    'roberta_pos' : scores[2]\n",
    "}\n",
    "print(scores_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "567e7595",
   "metadata": {},
   "outputs": [],
   "source": [
    "train['review_length'] = train['review'].apply(lambda x: len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "fb2d4592",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>review</th>\n",
       "      <th>review_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>c77111d1e3526ac0f7cf13af46b65e65</td>\n",
       "      <td>1</td>\n",
       "      <td>I thought the film could be a bit more complex...</td>\n",
       "      <td>992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>c4806c50f6560aa65f15ed69a25940f2</td>\n",
       "      <td>0</td>\n",
       "      <td>...except for Jon Heder. This guy tanked the e...</td>\n",
       "      <td>842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>82b113c68594c74ab8dbe630206ec28a</td>\n",
       "      <td>1</td>\n",
       "      <td>Jim Carrey is good as usual, and even though t...</td>\n",
       "      <td>494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3d9891905de05248dfc2550239bd4687</td>\n",
       "      <td>1</td>\n",
       "      <td>Just read the original story which is written ...</td>\n",
       "      <td>370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>da8d5a23f01e129b534022149825caa2</td>\n",
       "      <td>1</td>\n",
       "      <td>I watched this film over a hundred times. It i...</td>\n",
       "      <td>177</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 id  sentiment  \\\n",
       "0  c77111d1e3526ac0f7cf13af46b65e65          1   \n",
       "1  c4806c50f6560aa65f15ed69a25940f2          0   \n",
       "2  82b113c68594c74ab8dbe630206ec28a          1   \n",
       "3  3d9891905de05248dfc2550239bd4687          1   \n",
       "4  da8d5a23f01e129b534022149825caa2          1   \n",
       "\n",
       "                                              review  review_length  \n",
       "0  I thought the film could be a bit more complex...            992  \n",
       "1  ...except for Jon Heder. This guy tanked the e...            842  \n",
       "2  Jim Carrey is good as usual, and even though t...            494  \n",
       "3  Just read the original story which is written ...            370  \n",
       "4  I watched this film over a hundred times. It i...            177  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "8ae131e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    12500.000000\n",
       "mean      1316.745120\n",
       "std        998.130579\n",
       "min         52.000000\n",
       "25%        701.000000\n",
       "50%        970.000000\n",
       "75%       1593.000000\n",
       "max       9432.000000\n",
       "Name: review_length, dtype: float64"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['review_length'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ea6b115b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>review</th>\n",
       "      <th>review_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>2da40a4b5698f815c98198e05bd7652b</td>\n",
       "      <td>0</td>\n",
       "      <td>After just finishing the book the same day I w...</td>\n",
       "      <td>2373</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  id  sentiment  \\\n",
       "26  2da40a4b5698f815c98198e05bd7652b          0   \n",
       "\n",
       "                                               review  review_length  \n",
       "26  After just finishing the book the same day I w...           2373  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[train['id']=='2da40a4b5698f815c98198e05bd7652b']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "7534f9d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(1, 'C:/Users/ranas/ML course/Competitions/Second competition/functions')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "202fa379",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e89745834f1a4dee9ae314b32e92f3fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from data_preprocess import light_text_cleaning\n",
    "train = light_text_cleaning(train, 'review')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "efa68116",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>review</th>\n",
       "      <th>review_length</th>\n",
       "      <th>tidy_review</th>\n",
       "      <th>tidy_review_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>c77111d1e3526ac0f7cf13af46b65e65</td>\n",
       "      <td>1</td>\n",
       "      <td>I thought the film could be a bit more complex...</td>\n",
       "      <td>992</td>\n",
       "      <td>I thought the film could be a bit more complex...</td>\n",
       "      <td>960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>c4806c50f6560aa65f15ed69a25940f2</td>\n",
       "      <td>0</td>\n",
       "      <td>...except for Jon Heder. This guy tanked the e...</td>\n",
       "      <td>842</td>\n",
       "      <td>...except for Jon Heder. This guy tanked the e...</td>\n",
       "      <td>816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>82b113c68594c74ab8dbe630206ec28a</td>\n",
       "      <td>1</td>\n",
       "      <td>Jim Carrey is good as usual, and even though t...</td>\n",
       "      <td>494</td>\n",
       "      <td>Jim Carrey is good as usual, and even though t...</td>\n",
       "      <td>470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3d9891905de05248dfc2550239bd4687</td>\n",
       "      <td>1</td>\n",
       "      <td>Just read the original story which is written ...</td>\n",
       "      <td>370</td>\n",
       "      <td>Just read the original story which is written ...</td>\n",
       "      <td>368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>da8d5a23f01e129b534022149825caa2</td>\n",
       "      <td>1</td>\n",
       "      <td>I watched this film over a hundred times. It i...</td>\n",
       "      <td>177</td>\n",
       "      <td>I watched this film over a hundred times. It i...</td>\n",
       "      <td>177</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 id  sentiment  \\\n",
       "0  c77111d1e3526ac0f7cf13af46b65e65          1   \n",
       "1  c4806c50f6560aa65f15ed69a25940f2          0   \n",
       "2  82b113c68594c74ab8dbe630206ec28a          1   \n",
       "3  3d9891905de05248dfc2550239bd4687          1   \n",
       "4  da8d5a23f01e129b534022149825caa2          1   \n",
       "\n",
       "                                              review  review_length  \\\n",
       "0  I thought the film could be a bit more complex...            992   \n",
       "1  ...except for Jon Heder. This guy tanked the e...            842   \n",
       "2  Jim Carrey is good as usual, and even though t...            494   \n",
       "3  Just read the original story which is written ...            370   \n",
       "4  I watched this film over a hundred times. It i...            177   \n",
       "\n",
       "                                         tidy_review  tidy_review_length  \n",
       "0  I thought the film could be a bit more complex...                 960  \n",
       "1  ...except for Jon Heder. This guy tanked the e...                 816  \n",
       "2  Jim Carrey is good as usual, and even though t...                 470  \n",
       "3  Just read the original story which is written ...                 368  \n",
       "4  I watched this film over a hundred times. It i...                 177  "
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "29ed5f43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    12500.000000\n",
       "mean      1285.745840\n",
       "std        974.362788\n",
       "min         52.000000\n",
       "25%        688.000000\n",
       "50%        948.000000\n",
       "75%       1557.250000\n",
       "max       9331.000000\n",
       "Name: tidy_review_length, dtype: float64"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['tidy_review_length'] = train['tidy_review'].apply(lambda x: len(x))\n",
    "train['tidy_review_length'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "3af3b4d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def polarity_scores_roberta(example):\n",
    "    encoded_text = tokenizer(example, max_length = 511, return_tensors='pt')\n",
    "    output = model(**encoded_text)\n",
    "    scores = output[0][0].detach().numpy()\n",
    "    scores = softmax(scores)\n",
    "    scores_dict = {\n",
    "        'roberta_neg' : scores[0],\n",
    "        'roberta_neu' : scores[1],\n",
    "        'roberta_pos' : scores[2]\n",
    "    }\n",
    "    return scores_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "27e8aa02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0926dfca32894d25882412f1c027f577",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_14648\\1415603360.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m         \u001b[0mtext\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrow\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'review'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m         \u001b[0mmyid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrow\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'id'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m         \u001b[0mroberta_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpolarity_scores_roberta\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m         \u001b[0mres\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mmyid\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mroberta_result\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_14648\\3751126518.py\u001b[0m in \u001b[0;36mpolarity_scores_roberta\u001b[1;34m(example)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mpolarity_scores_roberta\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mexample\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[0mencoded_text\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mexample\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_length\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m511\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreturn_tensors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'pt'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mencoded_text\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m     \u001b[0mscores\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mscores\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msoftmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1188\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1189\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1190\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1191\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1192\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\transformers\\models\\roberta\\modeling_roberta.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, labels, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m   1206\u001b[0m         \u001b[0mreturn_dict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mreturn_dict\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mreturn_dict\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0muse_return_dict\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1207\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1208\u001b[1;33m         outputs = self.roberta(\n\u001b[0m\u001b[0;32m   1209\u001b[0m             \u001b[0minput_ids\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1210\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1188\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1189\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1190\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1191\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1192\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\transformers\\models\\roberta\\modeling_roberta.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m    844\u001b[0m             \u001b[0mpast_key_values_length\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpast_key_values_length\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    845\u001b[0m         )\n\u001b[1;32m--> 846\u001b[1;33m         encoder_outputs = self.encoder(\n\u001b[0m\u001b[0;32m    847\u001b[0m             \u001b[0membedding_output\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    848\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mextended_attention_mask\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1188\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1189\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1190\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1191\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1192\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\transformers\\models\\roberta\\modeling_roberta.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m    518\u001b[0m                 )\n\u001b[0;32m    519\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 520\u001b[1;33m                 layer_outputs = layer_module(\n\u001b[0m\u001b[0;32m    521\u001b[0m                     \u001b[0mhidden_states\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    522\u001b[0m                     \u001b[0mattention_mask\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1188\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1189\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1190\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1191\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1192\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\transformers\\models\\roberta\\modeling_roberta.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[0;32m    403\u001b[0m         \u001b[1;31m# decoder uni-directional self-attention cached key/values tuple is at positions 1,2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    404\u001b[0m         \u001b[0mself_attn_past_key_value\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpast_key_value\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mpast_key_value\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 405\u001b[1;33m         self_attention_outputs = self.attention(\n\u001b[0m\u001b[0;32m    406\u001b[0m             \u001b[0mhidden_states\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    407\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1188\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1189\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1190\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1191\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1192\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\transformers\\models\\roberta\\modeling_roberta.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[0;32m    330\u001b[0m         \u001b[0moutput_attentions\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mbool\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    331\u001b[0m     ) -> Tuple[torch.Tensor]:\n\u001b[1;32m--> 332\u001b[1;33m         self_outputs = self.self(\n\u001b[0m\u001b[0;32m    333\u001b[0m             \u001b[0mhidden_states\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    334\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1188\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1189\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1190\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1191\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1192\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\transformers\\models\\roberta\\modeling_roberta.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[0;32m    217\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    218\u001b[0m             \u001b[0mkey_layer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtranspose_for_scores\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 219\u001b[1;33m             \u001b[0mvalue_layer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtranspose_for_scores\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    220\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    221\u001b[0m         \u001b[0mquery_layer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtranspose_for_scores\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmixed_query_layer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1188\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1189\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1190\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1191\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1192\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\linear.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    112\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    113\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 114\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    115\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    116\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "res = {}\n",
    "for i, row in tqdm(train.iterrows(), total=len(train)):\n",
    "    try:\n",
    "        text = row['review']\n",
    "        myid = row['id']\n",
    "        roberta_result = polarity_scores_roberta(text)\n",
    "        res[myid] = roberta_result\n",
    "    except RuntimeError:\n",
    "        print(f'Broke for id {myid}')\n",
    "        res[myid] = {\n",
    "        'roberta_neg' : 0.5,\n",
    "        'roberta_neu' : 0.5,\n",
    "        'roberta_pos' : 0.5\n",
    "        }\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "7ece5ee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = pd.DataFrame(res).T\n",
    "results_df = results_df.reset_index().rename(columns={'index': 'id'})\n",
    "results_df = results_df.merge(train, how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "5b394719",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>roberta_neg</th>\n",
       "      <th>roberta_neu</th>\n",
       "      <th>roberta_pos</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>review</th>\n",
       "      <th>review_length</th>\n",
       "      <th>tidy_review</th>\n",
       "      <th>tidy_review_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>c77111d1e3526ac0f7cf13af46b65e65</td>\n",
       "      <td>0.005072</td>\n",
       "      <td>0.047951</td>\n",
       "      <td>0.946977</td>\n",
       "      <td>1</td>\n",
       "      <td>I thought the film could be a bit more complex...</td>\n",
       "      <td>992</td>\n",
       "      <td>I thought the film could be a bit more complex...</td>\n",
       "      <td>960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>c4806c50f6560aa65f15ed69a25940f2</td>\n",
       "      <td>0.476714</td>\n",
       "      <td>0.350946</td>\n",
       "      <td>0.172340</td>\n",
       "      <td>0</td>\n",
       "      <td>...except for Jon Heder. This guy tanked the e...</td>\n",
       "      <td>842</td>\n",
       "      <td>...except for Jon Heder. This guy tanked the e...</td>\n",
       "      <td>816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>82b113c68594c74ab8dbe630206ec28a</td>\n",
       "      <td>0.046676</td>\n",
       "      <td>0.100293</td>\n",
       "      <td>0.853030</td>\n",
       "      <td>1</td>\n",
       "      <td>Jim Carrey is good as usual, and even though t...</td>\n",
       "      <td>494</td>\n",
       "      <td>Jim Carrey is good as usual, and even though t...</td>\n",
       "      <td>470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3d9891905de05248dfc2550239bd4687</td>\n",
       "      <td>0.003896</td>\n",
       "      <td>0.050801</td>\n",
       "      <td>0.945302</td>\n",
       "      <td>1</td>\n",
       "      <td>Just read the original story which is written ...</td>\n",
       "      <td>370</td>\n",
       "      <td>Just read the original story which is written ...</td>\n",
       "      <td>368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>da8d5a23f01e129b534022149825caa2</td>\n",
       "      <td>0.001529</td>\n",
       "      <td>0.008747</td>\n",
       "      <td>0.989724</td>\n",
       "      <td>1</td>\n",
       "      <td>I watched this film over a hundred times. It i...</td>\n",
       "      <td>177</td>\n",
       "      <td>I watched this film over a hundred times. It i...</td>\n",
       "      <td>177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4995</th>\n",
       "      <td>a84e26db8a4410059b521dff427ec7c1</td>\n",
       "      <td>0.961930</td>\n",
       "      <td>0.034520</td>\n",
       "      <td>0.003550</td>\n",
       "      <td>0</td>\n",
       "      <td>This movie was bad from the start. The only pu...</td>\n",
       "      <td>760</td>\n",
       "      <td>This movie was bad from the start. The only pu...</td>\n",
       "      <td>760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4996</th>\n",
       "      <td>9c1a0d87818cc8a77d3c9acb8ff33452</td>\n",
       "      <td>0.751652</td>\n",
       "      <td>0.215149</td>\n",
       "      <td>0.033199</td>\n",
       "      <td>0</td>\n",
       "      <td>After having seen the movie the first question...</td>\n",
       "      <td>601</td>\n",
       "      <td>After having seen the movie the first question...</td>\n",
       "      <td>598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4997</th>\n",
       "      <td>a272bcf0561628bd50590b52e0bc657a</td>\n",
       "      <td>0.840266</td>\n",
       "      <td>0.138615</td>\n",
       "      <td>0.021119</td>\n",
       "      <td>0</td>\n",
       "      <td>How do comments like the one that was the head...</td>\n",
       "      <td>1352</td>\n",
       "      <td>How do comments like the one that was the head...</td>\n",
       "      <td>1352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4998</th>\n",
       "      <td>de606367278a2a23578d188a55f733de</td>\n",
       "      <td>0.025093</td>\n",
       "      <td>0.183860</td>\n",
       "      <td>0.791047</td>\n",
       "      <td>1</td>\n",
       "      <td>A masterful treatment of James Caine's \\The Po...</td>\n",
       "      <td>862</td>\n",
       "      <td>A masterful treatment of James Caine's \\The Po...</td>\n",
       "      <td>846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4999</th>\n",
       "      <td>790048674c3763717305b59e2c214c4b</td>\n",
       "      <td>0.507528</td>\n",
       "      <td>0.376595</td>\n",
       "      <td>0.115877</td>\n",
       "      <td>0</td>\n",
       "      <td>The movie starts out with some scrolling text ...</td>\n",
       "      <td>737</td>\n",
       "      <td>The movie starts out with some scrolling text ...</td>\n",
       "      <td>737</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5000 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    id  roberta_neg  roberta_neu  roberta_pos  \\\n",
       "0     c77111d1e3526ac0f7cf13af46b65e65     0.005072     0.047951     0.946977   \n",
       "1     c4806c50f6560aa65f15ed69a25940f2     0.476714     0.350946     0.172340   \n",
       "2     82b113c68594c74ab8dbe630206ec28a     0.046676     0.100293     0.853030   \n",
       "3     3d9891905de05248dfc2550239bd4687     0.003896     0.050801     0.945302   \n",
       "4     da8d5a23f01e129b534022149825caa2     0.001529     0.008747     0.989724   \n",
       "...                                ...          ...          ...          ...   \n",
       "4995  a84e26db8a4410059b521dff427ec7c1     0.961930     0.034520     0.003550   \n",
       "4996  9c1a0d87818cc8a77d3c9acb8ff33452     0.751652     0.215149     0.033199   \n",
       "4997  a272bcf0561628bd50590b52e0bc657a     0.840266     0.138615     0.021119   \n",
       "4998  de606367278a2a23578d188a55f733de     0.025093     0.183860     0.791047   \n",
       "4999  790048674c3763717305b59e2c214c4b     0.507528     0.376595     0.115877   \n",
       "\n",
       "      sentiment                                             review  \\\n",
       "0             1  I thought the film could be a bit more complex...   \n",
       "1             0  ...except for Jon Heder. This guy tanked the e...   \n",
       "2             1  Jim Carrey is good as usual, and even though t...   \n",
       "3             1  Just read the original story which is written ...   \n",
       "4             1  I watched this film over a hundred times. It i...   \n",
       "...         ...                                                ...   \n",
       "4995          0  This movie was bad from the start. The only pu...   \n",
       "4996          0  After having seen the movie the first question...   \n",
       "4997          0  How do comments like the one that was the head...   \n",
       "4998          1  A masterful treatment of James Caine's \\The Po...   \n",
       "4999          0  The movie starts out with some scrolling text ...   \n",
       "\n",
       "      review_length                                        tidy_review  \\\n",
       "0               992  I thought the film could be a bit more complex...   \n",
       "1               842  ...except for Jon Heder. This guy tanked the e...   \n",
       "2               494  Jim Carrey is good as usual, and even though t...   \n",
       "3               370  Just read the original story which is written ...   \n",
       "4               177  I watched this film over a hundred times. It i...   \n",
       "...             ...                                                ...   \n",
       "4995            760  This movie was bad from the start. The only pu...   \n",
       "4996            601  After having seen the movie the first question...   \n",
       "4997           1352  How do comments like the one that was the head...   \n",
       "4998            862  A masterful treatment of James Caine's \\The Po...   \n",
       "4999            737  The movie starts out with some scrolling text ...   \n",
       "\n",
       "      tidy_review_length  \n",
       "0                    960  \n",
       "1                    816  \n",
       "2                    470  \n",
       "3                    368  \n",
       "4                    177  \n",
       "...                  ...  \n",
       "4995                 760  \n",
       "4996                 598  \n",
       "4997                1352  \n",
       "4998                 846  \n",
       "4999                 737  \n",
       "\n",
       "[5000 rows x 9 columns]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "d5f48da4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9285581942327769"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "roc_auc_score(results_df['sentiment'], results_df['roberta_pos'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3097ace6",
   "metadata": {},
   "source": [
    "Так долго ждать, а результат не очень-то уже и хороший"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45e72d4f",
   "metadata": {},
   "source": [
    "Посмотрим на чистоту данных ещё раз"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "a073c355",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Jim Carrey is good as usual, and even though there are quite a few \\\\Jim Carrey moments\\\\\", it\\'s definitely not a \\\\\"Jim Carrey movie\\\\\".It\\'s targeted mostly at children, and I managed to enjoy it as such movie. It was promoted in Israel as another Jim Carrey movie, so those who expected a weird over the top comedy were disappointed.The movie has nice moments and works well as a movie for kids. I can\\'t say I LOVED this movie, but then again I\\'m not its target audience!\"'"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['tidy_review'][2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "344db8ff",
   "metadata": {},
   "source": [
    "Сделаем случайную выборку с довольно маленькими отзывами"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "da5fcecc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>review</th>\n",
       "      <th>review_length</th>\n",
       "      <th>tidy_review</th>\n",
       "      <th>tidy_review_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>c77111d1e3526ac0f7cf13af46b65e65</td>\n",
       "      <td>1</td>\n",
       "      <td>I thought the film could be a bit more complex...</td>\n",
       "      <td>992</td>\n",
       "      <td>I thought the film could be a bit more complex...</td>\n",
       "      <td>960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>c4806c50f6560aa65f15ed69a25940f2</td>\n",
       "      <td>0</td>\n",
       "      <td>...except for Jon Heder. This guy tanked the e...</td>\n",
       "      <td>842</td>\n",
       "      <td>...except for Jon Heder. This guy tanked the e...</td>\n",
       "      <td>816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>82b113c68594c74ab8dbe630206ec28a</td>\n",
       "      <td>1</td>\n",
       "      <td>Jim Carrey is good as usual, and even though t...</td>\n",
       "      <td>494</td>\n",
       "      <td>Jim Carrey is good as usual, and even though t...</td>\n",
       "      <td>470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3d9891905de05248dfc2550239bd4687</td>\n",
       "      <td>1</td>\n",
       "      <td>Just read the original story which is written ...</td>\n",
       "      <td>370</td>\n",
       "      <td>Just read the original story which is written ...</td>\n",
       "      <td>368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>da8d5a23f01e129b534022149825caa2</td>\n",
       "      <td>1</td>\n",
       "      <td>I watched this film over a hundred times. It i...</td>\n",
       "      <td>177</td>\n",
       "      <td>I watched this film over a hundred times. It i...</td>\n",
       "      <td>177</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 id  sentiment  \\\n",
       "0  c77111d1e3526ac0f7cf13af46b65e65          1   \n",
       "1  c4806c50f6560aa65f15ed69a25940f2          0   \n",
       "2  82b113c68594c74ab8dbe630206ec28a          1   \n",
       "3  3d9891905de05248dfc2550239bd4687          1   \n",
       "4  da8d5a23f01e129b534022149825caa2          1   \n",
       "\n",
       "                                              review  review_length  \\\n",
       "0  I thought the film could be a bit more complex...            992   \n",
       "1  ...except for Jon Heder. This guy tanked the e...            842   \n",
       "2  Jim Carrey is good as usual, and even though t...            494   \n",
       "3  Just read the original story which is written ...            370   \n",
       "4  I watched this film over a hundred times. It i...            177   \n",
       "\n",
       "                                         tidy_review  tidy_review_length  \n",
       "0  I thought the film could be a bit more complex...                 960  \n",
       "1  ...except for Jon Heder. This guy tanked the e...                 816  \n",
       "2  Jim Carrey is good as usual, and even though t...                 470  \n",
       "3  Just read the original story which is written ...                 368  \n",
       "4  I watched this film over a hundred times. It i...                 177  "
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "036270fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sample = train"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
