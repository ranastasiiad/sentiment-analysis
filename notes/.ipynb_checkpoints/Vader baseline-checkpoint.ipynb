{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8251badf",
   "metadata": {},
   "source": [
    "Valence Aware Dictionary for sEntiment Reasoning\n",
    "\n",
    "his lexical dictionary does not only contain words, but also phrases (such as “bad ass” and “the bomb”), emoticons (such as “:-)”) and sentiment-laden acronyms (such as “ROFL” and “WTF”). All the lexical features were rated for the polarity and intensity on a scale from “-4: Extremely Negative” to “+4 Extremely Positive” by 10 independent human raters. The average score is then used as the sentiment indicator for each lexical feature in the dictionary. For example, in Vader, the word “okay” has a positive rating of 0.9, “good” is 1.9 and “great” is 3.1, whereas “horrible” is -2.5, the frowning emoticon “:(“ is -2.2, and “sucks” is -1.5. Vader’s lexicon dictionary contains around 7,500 sentiment features in total and any word not listed in the dictionary will be scored as “0: Neutral”."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c7d6e5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "nltk.download('vader_lexicon')\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "sia = SentimentIntensityAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ccfae89",
   "metadata": {},
   "outputs": [],
   "source": [
    "sia.polarity_scores('I am so happy!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be5c7f6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = {}\n",
    "for i, row in tqdm(train_df.iterrows(), total=len(train_df)):\n",
    "    text = row['tidy_review']\n",
    "    myid = row['id']\n",
    "    res[myid] = sia.polarity_scores(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6e390c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "vaders = pd.DataFrame(res).T\n",
    "vaders = vaders.reset_index().rename(columns={'index': 'id'})\n",
    "vaders = vaders.merge(train_df, how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39f2e5c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "vaders.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0832cf78",
   "metadata": {},
   "outputs": [],
   "source": [
    "vaders['predict'] = np.where(vaders['compound']>0,1,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55233340",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "train_metric = roc_auc_score(\n",
    "    y_true=vaders['sentiment'],\n",
    "    y_score=vaders['predict']\n",
    ")\n",
    "\n",
    "print(f\"train_roc_auc: {round(train_metric, 4)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
